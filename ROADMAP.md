### Fase 1 – Fundação mínima para interação

- [x]  Ativar escuta por voz (via hotkey)
- [x]  Gravar áudio via `sounddevice`
- [x]  Transcrever com `faster-whisper`
- [x]  Enviar texto para IA local (OpenHermes/Ollama)
- [ ]  Executar comandos simples com voz (abrir apps, timers)
- [ ]  Armazenar interações em SQLite
- [ ]  Buscar interações anteriores por comandos
- [ ]  Reconhecer comandos como "modo estudo", "modo foco"
- [ ]  Executar rotinas (abrir VSCode, Udemy etc.)
- [ ]  Registrar todas as interações (texto, resposta, hora)
- [ ]  Responder à pergunta “o que fiz hoje?”
- [ ]  Criar lembretes via comando de voz
- [ ]  Alertar com voz (say) ou notificação de sistema

### Fase 2 – Núcleo de utilidade pessoal

- [ ]  Gerar briefing matinal com metas e compromissos
- [ ]  Gerar resumo noturno com base no histórico
- [ ]  Criar log de produtividade (ações, tempo focado)
- [ ]  Criar dashboard local simples (HTML ou texto)

### Fase 3 – Monitoramento e planejamento

- [ ]  Criar sistema de metas com prazos e marcos
- [ ]  Alertar sobre progresso e pendências
- [ ]  Criar tarefas por texto ou voz
- [ ]  Marcar tarefas como concluídas, listar e deletar
- [ ]  Armazenamento local de tarefas

### Fase 4 – Integrações e contexto

- [ ]  Ler eventos do Apple Calendar (.ics)
- [ ]  Criar eventos no calendário via AppleScript
- [ ]  Enviar mensagens pelo Apple Messages (osascript)
- [ ]  Receber comandos por texto via Messages